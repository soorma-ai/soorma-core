# Memory System: User Guide

**Status:** ✅ Stage 2 Complete (January 30, 2026)  
**Last Updated:** February 15, 2026  
**Related Stages:** Stage 2 (RF-ARCH-008, RF-ARCH-009, RF-SDK-006, RF-SDK-007, RF-SDK-008), Stage 2.1 (RF-ARCH-012, RF-ARCH-013, RF-ARCH-014)

---

## Overview

Soorma's Memory Service implements the **CoALA (Cognitive Architectures for Language Agents)** framework, providing four distinct memory types modeled after human cognition:

| Memory Type | Purpose | Lifespan | Access Pattern |
|-------------|---------|----------|----------------|
| **Semantic** | Knowledge & facts | Long-term | Similarity search |
| **Episodic** | Interaction history | Long-term | Temporal + similarity |
| **Procedural** | Skills & prompts | Long-term | Context-based |
| **Working** | Workflow state | Temporary (plan-scoped) | Key-value |

### When to Use Each Memory Type

```
Need to store...
├─ Knowledge/facts for search?
│  └─ Use SEMANTIC MEMORY (examples/04-memory-semantic)
│
├─ Conversation history?
│  └─ Use EPISODIC MEMORY (examples/06-memory-episodic)
│
├─ Dynamic prompts/skills?
│  └─ Use PROCEDURAL MEMORY
│
└─ Temporary workflow state?
   └─ Use WORKING MEMORY (examples/05-memory-working)
```

---

## Memory Types

### Semantic Memory

**What It's For:** Store knowledge and facts retrieved via similarity search.

**Use Cases:**
- ✅ Knowledge bases and documentation
- ✅ RAG (Retrieval-Augmented Generation) workflows
- ✅ Fact storage for LLM context augmentation
- ✅ Domain-specific information
- ❌ Temporary workflow data → Use Working Memory
- ❌ Conversation logs → Use Episodic Memory

**API Example:**

```python
from soorma import PlatformContext

async with PlatformContext() as context:
    # Store knowledge
    await context.memory.store_knowledge(
        content="Python was created by Guido van Rossum in 1991.",
        metadata={"category": "programming", "language": "python"}
    )
    
    # Search by similarity
    results = await context.memory.search_knowledge(
        query="Who created Python?",
        limit=5
    )
```

**Key Characteristics:**
- **Embeddings:** Automatically generated by Memory Service
- **Search:** Vector similarity (semantic, not keyword)
- **Scope:** Tenant-wide (shared across agents), with optional user/agent-level restrictions
- **Persistence:** Long-term

**User Identity in Semantic Memory:**

The `user_id` parameter represents **either a human user OR an autonomous agent identity**:

```python
# Human-driven system: user_id = end user
await context.memory.store_knowledge(
    content="Customer preferences...",
    user_id="alice",  # Human end user
    metadata={"source": "conversation"}
)

# Autonomous agent system: user_id = agent identity
await context.memory.store_knowledge(
    content="Market research findings...",
    user_id="research-agent",  # Agent identity
    metadata={"source": "automated-scan"}
)

# Shared knowledge base: use system/service account
await context.memory.store_knowledge(
    content="Company policies...",
    user_id="knowledge-base",  # System account
    metadata={"category": "policies"}
)
```

**Best Practices:**
1. **Chunk large documents:** Store paragraphs or sections, not entire books
2. **Use metadata:** Tag content for organization and future filtering
3. **Test queries:** Semantic search may surprise you
4. **Batch inserts:** Use parallel operations for bulk data

**Pattern: RAG Workflow**

```python
# 1. Retrieve relevant knowledge
knowledge = await context.memory.search_knowledge(
    query="What is Docker?",
    limit=3
)

# 2. Build context
context_text = "\n\n".join([k.content for k in knowledge])

# 3. Augment LLM prompt
prompt = f"Context:\n{context_text}\n\nQuestion: {user_question}"
response = llm.complete(prompt)
```

**Example:** [examples/04-memory-semantic](../../examples/04-memory-semantic/)

---

### Episodic Memory

**What It's For:** Store interaction history between users and agents.

**Use Cases:**
- ✅ Multi-turn conversations
- ✅ User interaction logging
- ✅ Conversation context for LLMs
- ✅ Audit trails
- ✅ Personalization
- ❌ Workflow task state → Use Working Memory
- ❌ General knowledge → Use Semantic Memory

**API Example:**

```python
# Log interaction
await context.memory.log_interaction(
    agent_id="chat-agent",
    role="user",
    content="What is Python?",
    user_id="user123",
    metadata={"session_id": "session-456"}
)

# Get recent history (context window)
history = await context.memory.get_recent_history(
    agent_id="chat-agent",
    user_id="user123",
    limit=10  # Last 10 interactions
)

# Search past interactions (long-term recall)
relevant = await context.memory.search_interactions(
    agent_id="chat-agent",
    query="Python programming",
    user_id="user123",
    limit=5
)
```

**Key Characteristics:**
- **Roles:** user, assistant, system, tool
- **Scoped:** By agent_id AND user_id
- **Access:** Temporal (recent) OR similarity (search)
- **Persistence:** Long-term

**Best Practices:**
1. **Log both sides:** Always log user input AND agent response
2. **Use metadata:** Store session_id, timestamps, context
3. **Limit context window:** Don't load entire history (10-20 interactions typical)
4. **Search for recall:** Use semantic search for relevant past context

**Pattern: Context Window for LLM**

```python
# Get recent conversation history
history = await context.memory.get_recent_history(
    agent_id="my-agent",
    user_id=user_id,
    limit=10
)

# Convert to LLM message format
messages = [
    {"role": h.role, "content": h.content}
    for h in history
]

# Add system prompt
messages.insert(0, {
    "role": "system",
    "content": "You are a helpful assistant."
})

# Generate response with context
response = llm.complete(messages)

# Log assistant response
await context.memory.log_interaction(
    agent_id="my-agent",
    role="assistant",
    content=response,
    user_id=user_id
)
```

**Example:** [examples/06-memory-episodic](../../examples/06-memory-episodic/)

---

### Procedural Memory

**What It's For:** Store dynamic prompts, rules, and skills retrieved based on context.

**Use Cases:**
- ✅ System prompts that adapt to context
- ✅ Few-shot examples
- ✅ Agent skills and capabilities
- ✅ Dynamic rules and policies
- ❌ Static facts → Use Semantic Memory
- ❌ Conversation logs → Use Episodic Memory
- ❌ Temporary state → Use Working Memory

**API Example:**

```python
# Get relevant skills for current context
skills = await context.memory.get_relevant_skills(
    agent_id="my-agent",
    context="User wants to analyze data",
    user_id=user_id,
    limit=3
)

# Use skills in prompt
for skill in skills:
    prompt += f"\n{skill.content}"
```

**Best Practices:**
1. **Store variations:** Different versions for different scenarios
2. **Use metadata:** Tag skills by difficulty, domain, etc.
3. **Test retrieval:** Ensure right skills surface for given context
4. **Version skills:** Update based on performance

**Pattern: Dynamic Prompt Selection**

```python
# Get relevant skills/prompts
skills = await context.memory.get_relevant_skills(
    agent_id="data-analyst",
    context=f"Analyze {data_type} data for {goal}",
    user_id=user_id,
    limit=2
)

# Build adaptive system prompt
system_prompt = "You are a data analyst.\n\nSkills:\n"
system_prompt += "\n".join([s.content for s in skills])

# Use in LLM call
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_request}
]
```

---

### Working Memory

**What It's For:** Store temporary, plan-scoped state for multi-agent workflows.

**Use Cases:**
- ✅ Multi-agent workflow state
- ✅ Passing data between choreographed agents
- ✅ Tracking workflow progress
- ✅ Temporary task decomposition
- ❌ Long-term knowledge → Use Semantic Memory
- ❌ Conversation history → Use Episodic Memory
- ❌ Cross-plan data (not isolated)

**API Examples:**

#### Manual API (Verbose)

```python
# Store state
await context.memory.set_plan_state(
    plan_id="plan-123",
    key="research_data",
    value={"findings": [...]}
)

# Retrieve state
response = await context.memory.get_plan_state(
    plan_id="plan-123",
    key="research_data"
)
data = response.value
```

#### WorkflowState Helper (Recommended)

```python
from soorma.workflow import WorkflowState

# Initialize
state = WorkflowState(context.memory, plan_id)

# Store/retrieve (8x less code!)
await state.set("research_data", {"findings": [...]})
data = await state.get("research_data")

# Track actions
await state.record_action("research.completed")
history = await state.get_action_history()
```

**Key Characteristics:**
- **Scoped:** By plan_id (isolated per workflow)
- **Temporary:** Cleared when workflow completes
- **Shared:** Accessible by all agents in same plan
- **Persistence:** Short-term (plan lifetime)

**Best Practices:**
1. **Always use plan_id:** Ensures isolation
2. **Use WorkflowState helper:** Reduces boilerplate by 8x
3. **Track action history:** `record_action()` creates audit trail
4. **Clean up:** Delete plan state when workflow finishes
5. **Handle missing keys:** `get()` returns None if key doesn't exist

**Pattern: Multi-Agent Handoff**

```python
# Agent A (Planner)
state = WorkflowState(context.memory, plan_id)
await state.set("goal", "Write blog post")
await state.set("tasks", ["research", "draft", "review"])

# Agent B (Researcher)
goal = await state.get("goal")
# ... do research ...
await state.set("research", findings)
await state.record_action("research.completed")

# Agent C (Writer)
research = await state.get("research")
# ... write draft using research ...
await state.set("draft", content)
await state.record_action("draft.completed")
```

**Pattern: Cleanup and Deletion**

Working memory is temporary and should be cleaned up:

```python
# Immediate cleanup - Remove sensitive data right after use
await state.set("api_key", key_value)
# ... use the key ...
deleted = await state.delete("api_key")

# Workflow cleanup - After workflow completes
count = await state.cleanup()  # Removes ALL state for this plan

# Alternative: Use context.memory for finer control
await context.memory.delete_plan_state(
    plan_id=plan_id,
    tenant_id=...,
    user_id=...
)
```

**When to cleanup:**
- ✅ After workflow completion (free resources)
- ✅ Immediately after using sensitive data
- ✅ Before archiving workflow execution
- ✅ In long-running systems handling many workflows
- ❌ During workflow execution (data still needed)

**Example:** [examples/05-memory-working](../../examples/05-memory-working/)

---

## Comparison Matrix

| Feature | Semantic | Episodic | Procedural | Working |
|---------|----------|----------|------------|---------|
| **Lifespan** | Long-term | Long-term | Long-term | Plan-scoped |
| **Scope** | Global | agent_id + user_id | agent_id | plan_id |
| **Search** | Similarity | Temporal + Similarity | Context-based | Key-value |
| **Use Case** | Knowledge | Conversations | Prompts | Workflow state |
| **Example** | "Python was created in 1991" | User: "What is Python?" | "When analyzing data..." | plan_data = {...} |

---

## Multi-Memory Patterns

### Pattern: RAG + Conversation Context

Combine semantic memory (knowledge) with episodic memory (history):

```python
# 1. Get conversation context
history = await context.memory.get_recent_history(
    agent_id="my-agent",
    user_id=user_id,
    limit=10
)

# 2. Search knowledge base
knowledge = await context.memory.search_knowledge(
    query=user_question,
    limit=3
)

# 3. Combine both
messages = [{"role": h.role, "content": h.content} for h in history]
context_text = "\n".join([k.content for k in knowledge])

messages.append({
    "role": "system",
    "content": f"Additional context:\n{context_text}"
})

# 4. Generate response
response = llm.complete(messages)
```

### Pattern: Workflow with Knowledge Retrieval

Combine working memory (state) with semantic memory (knowledge):

```python
# Worker accesses plan state
state = WorkflowState(context.memory, plan_id)
topic = await state.get("research_topic")

# Retrieve relevant knowledge
knowledge = await context.memory.search_knowledge(
    query=topic,
    limit=5
)

# Store findings in plan state
await state.set("research_findings", [k.content for k in knowledge])
await state.record_action("research.completed")
```

### Pattern: Full Context Agent

Combine all memory types:

```python
# 1. Working memory: Get current task context
state = WorkflowState(context.memory, plan_id)
task = await state.get("current_task")

# 2. Semantic memory: Get relevant knowledge
knowledge = await context.memory.search_knowledge(
    query=task["description"],
    limit=3
)

# 3. Episodic memory: Get conversation history
history = await context.memory.get_recent_history(
    agent_id=agent_id,
    user_id=user_id,
    limit=10
)

# 4. Procedural memory: Get relevant skills
skills = await context.memory.get_relevant_skills(
    agent_id=agent_id,
    context=task["description"],
    user_id=user_id,
    limit=2
)

# 5. Combine all contexts for LLM
# ... build comprehensive prompt ...
```

---

## Common Mistakes

### ❌ Using Working Memory for Long-term Data

```python
# WRONG: Will be lost when workflow completes
await state.set("important_fact", "...")
```

```python
# RIGHT: Use semantic memory for facts
await context.memory.store_knowledge(
    content="important_fact",
    metadata={...}
)
```

### ❌ Using Semantic Memory for Workflow State

```python
# WRONG: Not scoped to plan, hard to query
await context.memory.store_knowledge(
    content=f"Step 1 result: {data}"
)
```

```python
# RIGHT: Use working memory for workflow state
state = WorkflowState(context.memory, plan_id)
await state.set("step1_result", data)
```

### ❌ Not Scoping Episodic Properly

```python
# WRONG: Missing user_id breaks isolation
await context.memory.log_interaction(
    agent_id="my-agent",
    role="user",
    content=message
)
```

```python
# RIGHT: Always include user_id
await context.memory.log_interaction(
    agent_id="my-agent",
    role="user",
    content=message,
    user_id=user_id
)
```

### ❌ Loading Too Much History

```python
# WRONG: Expensive, exceeds LLM context limits
history = await context.memory.get_recent_history(
    agent_id="my-agent",
    user_id=user_id,
    limit=1000  # Way too much!
)
```

```python
# RIGHT: Reasonable context window
history = await context.memory.get_recent_history(
    agent_id="my-agent",
    user_id=user_id,
    limit=10  # ~5 turns
)
```

---

## Performance Tips

1. **Batch operations:** Use parallel async calls when possible
2. **Limit results:** Always specify reasonable limits for searches
3. **Cache frequently accessed data:** Don't fetch same knowledge repeatedly
4. **Use metadata:** Helps with future filtering capabilities
5. **Clean up:** Delete plan state after workflow completion to free resources

---

## Examples

- [examples/04-memory-semantic](../../examples/04-memory-semantic/) - Knowledge base and RAG
- [examples/05-memory-working](../../examples/05-memory-working/) - Workflow state with WorkflowState helper
- [examples/06-memory-episodic](../../examples/06-memory-episodic/) - Conversation history and context window

---

## Related Documentation

- [ARCHITECTURE.md](./ARCHITECTURE.md) - Technical design and implementation
- [Memory Service](../../services/memory/README.md) - Service implementation
- [SDK Memory Client](../../sdk/python/README.md#memory-client) - API reference
- [CoALA Framework Paper](https://arxiv.org/abs/2309.02427) - Research foundation
- [Refactoring Plan](../refactoring/sdk/02-MEMORY-SDK.md) - Stage 2 refactoring details
