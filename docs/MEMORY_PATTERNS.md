# Memory Patterns Guide

This guide explains when and how to use each of the four CoALA memory types in Soorma Core.

## Overview

Soorma's Memory Service implements the **CoALA (Cognitive Architectures for Language Agents)** framework, which provides four distinct memory types modeled after human cognition:

| Memory Type | Purpose | Lifespan | Access Pattern |
|-------------|---------|----------|----------------|
| **Semantic** | Knowledge & facts | Long-term | Similarity search |
| **Episodic** | Interaction history | Long-term | Temporal + similarity |
| **Procedural** | Skills & prompts | Long-term | Context-based |
| **Working** | Workflow state | Temporary (plan-scoped) | Key-value |

## When to Use Each Memory Type

### Quick Decision Tree

```
Need to store...
├─ Knowledge/facts for search?
│  └─ Use SEMANTIC MEMORY (examples/04-memory-semantic)
│
├─ Conversation history?
│  └─ Use EPISODIC MEMORY (examples/06-memory-episodic)
│
├─ Dynamic prompts/skills?
│  └─ Use PROCEDURAL MEMORY
│
└─ Temporary workflow state?
   └─ Use WORKING MEMORY (examples/05-memory-working)
```

---

## Semantic Memory

### What It's For

Store **knowledge and facts** that should be retrieved via similarity search.

### Use Cases

✅ **Perfect for:**
- Knowledge bases and documentation
- RAG (Retrieval-Augmented Generation) workflows
- Fact storage for LLM context augmentation
- Domain-specific information

❌ **Not suitable for:**
- Temporary workflow data → Use Working Memory
- Conversation logs → Use Episodic Memory
- Frequently changing data

### API Examples

```python
from soorma import PlatformContext

async with PlatformContext() as context:
    # Store knowledge
    await context.memory.store_knowledge(
        content="Python was created by Guido van Rossum in 1991.",
        metadata={"category": "programming", "language": "python"}
    )
    
    # Search by similarity
    results = await context.memory.search_knowledge(
        query="Who created Python?",
        limit=5
    )
```

### Key Characteristics

- **Embeddings**: Automatically generated by Memory Service
- **Search**: Vector similarity (semantic, not keyword)
- **Scope**: Tenant-wide (shared across agents), with optional user/agent-level restrictions
- **Persistence**: Long-term

### User Identity in Semantic Memory

**Important:** The `user_id` parameter in semantic memory operations represents **either a human user OR an autonomous agent identity**:

```python
# Human-driven system: user_id = end user
await context.memory.store_knowledge(
    content="Customer preferences...",
    user_id="alice",  # Human end user
    metadata={"source": "conversation"}
)

# Autonomous agent system: user_id = agent identity
await context.memory.store_knowledge(
    content="Market research findings...",
    user_id="research-agent",  # Agent identity
    metadata={"source": "automated-scan"}
)

# Shared knowledge base: use system/service account
await context.memory.store_knowledge(
    content="Company policies...",
    user_id="knowledge-base",  # System account for shared knowledge
    metadata={"category": "policies"}
)
```

**Why `user_id` is required:**
1. **Access control**: Enable optional restrictions (e.g., agent-specific knowledge)
2. **Audit trails**: Track whether knowledge was added by users or agents
3. **Future extensibility**: Support user/agent-specific overrides of shared knowledge

### Best Practices

1. **Chunk large documents**: Store paragraphs or sections, not entire books
2. **Use metadata**: Tag content for organization and future filtering
3. **Test queries**: Semantic search may surprise you - test with real questions
4. **Batch inserts**: Use parallel operations for bulk data

### Pattern: RAG Workflow

```python
# 1. Retrieve relevant knowledge
knowledge = await context.memory.search_knowledge(
    query="What is Docker?",
    limit=3
)

# 2. Build context
context_text = "\n\n".join([k.content for k in knowledge])

# 3. Augment LLM prompt
prompt = f"Context:\n{context_text}\n\nQuestion: {user_question}"
response = llm.complete(prompt)
```

**Example:** [examples/04-memory-semantic](../examples/04-memory-semantic/)

---

## Episodic Memory

### What It's For

Store **interaction history** between users and agents.

### Use Cases

✅ **Perfect for:**
- Multi-turn conversations
- User interaction logging
- Conversation context for LLMs
- Audit trails
- Personalization

❌ **Not suitable for:**
- Workflow task state → Use Working Memory
- General knowledge → Use Semantic Memory

### API Examples

```python
# Log interaction
await context.memory.log_interaction(
    agent_id="chat-agent",
    role="user",
    content="What is Python?",
    user_id="user123",
    metadata={"session_id": "session-456"}
)

# Get recent history (context window)
history = await context.memory.get_recent_history(
    agent_id="chat-agent",
    user_id="user123",
    limit=10  # Last 10 interactions
)

# Search past interactions (long-term recall)
relevant = await context.memory.search_interactions(
    agent_id="chat-agent",
    query="Python programming",
    user_id="user123",
    limit=5
)
```

### Key Characteristics

- **Roles**: user, assistant, system, tool
- **Scoped**: By agent_id AND user_id
- **Access**: Temporal (recent) OR similarity (search)
- **Persistence**: Long-term

### Best Practices

1. **Log both sides**: Always log user input AND agent response
2. **Use metadata**: Store session_id, timestamps, context
3. **Limit context window**: Don't load entire history (10-20 interactions typical)
4. **Search for recall**: Use semantic search to find relevant past context

### Pattern: Context Window for LLM

```python
# Get recent conversation history
history = await context.memory.get_recent_history(
    agent_id="my-agent",
    user_id=user_id,
    limit=10
)

# Convert to LLM message format
messages = [
    {"role": h.role, "content": h.content}
    for h in history
]

# Add system prompt
messages.insert(0, {
    "role": "system",
    "content": "You are a helpful assistant."
})

# Generate response with context
response = llm.complete(messages)

# Log assistant response
await context.memory.log_interaction(
    agent_id="my-agent",
    role="assistant",
    content=response,
    user_id=user_id
)
```

### Pattern: Long-term Recall

```python
# User asks: "What did we discuss about databases?"

# Search past interactions
relevant = await context.memory.search_interactions(
    agent_id="my-agent",
    query="databases",
    user_id=user_id,
    limit=5
)

# Build summary
summary = "\n".join([r.content for r in relevant])
```

**Example:** [examples/06-memory-episodic](../examples/06-memory-episodic/)

---

## Procedural Memory

### What It's For

Store **dynamic prompts, rules, and skills** that should be retrieved based on context.

### Use Cases

✅ **Perfect for:**
- System prompts that adapt to context
- Few-shot examples
- Agent skills and capabilities
- Dynamic rules and policies

❌ **Not suitable for:**
- Static facts → Use Semantic Memory
- Conversation logs → Use Episodic Memory
- Temporary state → Use Working Memory

### API Examples

```python
# Get relevant skills for current context
skills = await context.memory.get_relevant_skills(
    agent_id="my-agent",
    context="User wants to analyze data",
    user_id=user_id,
    limit=3
)

# Use skills in prompt
for skill in skills:
    prompt += f"\n{skill.content}"
```

### Key Characteristics

- **Context-based**: Retrieved based on current task/situation
- **Adaptive**: Different prompts for different scenarios
- **Scoped**: By agent_id (skills specific to agent capabilities)
- **Persistence**: Long-term

### Best Practices

1. **Store variations**: Different versions of prompts for different contexts
2. **Use metadata**: Tag skills by difficulty, domain, etc.
3. **Test retrieval**: Ensure right skills surface for given context
4. **Version skills**: Update skills over time based on performance

### Pattern: Dynamic Prompt Selection

```python
# Get relevant skills/prompts
skills = await context.memory.get_relevant_skills(
    agent_id="data-analyst",
    context=f"Analyze {data_type} data for {goal}",
    user_id=user_id,
    limit=2
)

# Build adaptive system prompt
system_prompt = "You are a data analyst.\n\nSkills:\n"
system_prompt += "\n".join([s.content for s in skills])

# Use in LLM call
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_request}
]
```

**Note:** Procedural memory examples coming in future releases.

---

## Working Memory

### What It's For

Store **temporary, plan-scoped state** for multi-agent workflows.

### Use Cases

✅ **Perfect for:**
- Multi-agent workflow state
- Passing data between choreographed agents
- Tracking workflow progress
- Temporary task decomposition

❌ **Not suitable for:**
- Long-term knowledge → Use Semantic Memory
- Conversation history → Use Episodic Memory
- Cross-plan data (not isolated)

### API Examples

#### Manual API (Verbose)

```python
# Store state
await context.memory.set_plan_state(
    plan_id="plan-123",
    key="research_data",
    value={"findings": [...]}
)

# Retrieve state
response = await context.memory.get_plan_state(
    plan_id="plan-123",
    key="research_data"
)
data = response.value
```

#### WorkflowState Helper (Recommended)

```python
from soorma.workflow import WorkflowState

# Initialize
state = WorkflowState(context.memory, plan_id)

# Store/retrieve (8x less code!)
await state.set("research_data", {"findings": [...]})
data = await state.get("research_data")

# Track actions
await state.record_action("research.completed")
history = await state.get_action_history()
```

### Key Characteristics

- **Scoped**: By plan_id (isolated per workflow)
- **Temporary**: Cleared when workflow completes
- **Shared**: Accessible by all agents in same plan
- **Persistence**: Short-term (plan lifetime)

### Best Practices

1. **Always use plan_id**: Ensures isolation between workflows
2. **Use WorkflowState helper**: Reduces boilerplate by 8x
3. **Track action history**: `record_action()` creates audit trail
4. **Clean up**: Delete plan state when workflow finishes (future enhancement)
5. **Handle missing keys**: `get()` returns None if key doesn't exist

### Pattern: Multi-Agent Handoff

```python
# Agent A (Planner)
state = WorkflowState(context.memory, plan_id)
await state.set("goal", "Write blog post")
await state.set("tasks", ["research", "draft", "review"])

# Agent B (Researcher)
goal = await state.get("goal")
# ... do research ...
await state.set("research", findings)
await state.record_action("research.completed")

# Agent C (Writer)
research = await state.get("research")
# ... write draft using research ...
await state.set("draft", content)
await state.record_action("draft.completed")
```

### Pattern: Progress Tracking

```python
# Initialize workflow
await state.set("status", "in_progress")
await state.set("current_stage", "research")

# Track each step
await state.record_action("research.started")
await state.record_action("research.completed")
await state.record_action("draft.started")

# Check progress
history = await state.get_action_history()
# ["research.started", "research.completed", "draft.started"]
```

**Example:** [examples/05-memory-working](../examples/05-memory-working/)

---

## Comparison Matrix

| Feature | Semantic | Episodic | Procedural | Working |
|---------|----------|----------|------------|---------|
| **Lifespan** | Long-term | Long-term | Long-term | Plan-scoped |
| **Scope** | Global | agent_id + user_id | agent_id | plan_id |
| **Search** | Similarity | Temporal + Similarity | Context-based | Key-value |
| **Use Case** | Knowledge base | Conversations | Dynamic prompts | Workflow state |
| **Example** | "Python was created in 1991" | User: "What is Python?" | "When analyzing data..." | plan_data = {...} |

---

## Multi-Memory Patterns

### Pattern: RAG + Conversation Context

Combine semantic memory (knowledge) with episodic memory (history):

```python
# 1. Get conversation context
history = await context.memory.get_recent_history(
    agent_id="my-agent",
    user_id=user_id,
    limit=10
)

# 2. Search knowledge base
knowledge = await context.memory.search_knowledge(
    query=user_question,
    limit=3
)

# 3. Combine both
messages = [{"role": h.role, "content": h.content} for h in history]
context_text = "\n".join([k.content for k in knowledge])

messages.append({
    "role": "system",
    "content": f"Additional context:\n{context_text}"
})

# 4. Generate response
response = llm.complete(messages)
```

### Pattern: Workflow with Knowledge Retrieval

Combine working memory (state) with semantic memory (knowledge):

```python
# Worker accesses plan state
state = WorkflowState(context.memory, plan_id)
topic = await state.get("research_topic")

# Retrieve relevant knowledge
knowledge = await context.memory.search_knowledge(
    query=topic,
    limit=5
)

# Store findings in plan state
await state.set("research_findings", [k.content for k in knowledge])
await state.record_action("research.completed")
```

### Pattern: Full Context Agent

Combine all three memory types:

```python
# 1. Working memory: Get current task context
state = WorkflowState(context.memory, plan_id)
task = await state.get("current_task")

# 2. Semantic memory: Get relevant knowledge
knowledge = await context.memory.search_knowledge(
    query=task["description"],
    limit=3
)

# 3. Episodic memory: Get conversation history
history = await context.memory.get_recent_history(
    agent_id=agent_id,
    user_id=user_id,
    limit=10
)

# 4. Procedural memory: Get relevant skills
skills = await context.memory.get_relevant_skills(
    agent_id=agent_id,
    context=task["description"],
    user_id=user_id,
    limit=2
)

# 5. Combine all contexts for LLM
# ... build comprehensive prompt ...
```

---

## Common Mistakes

### ❌ Using Working Memory for Long-term Data

```python
# WRONG: Will be lost when workflow completes
await state.set("important_fact", "...")
```

```python
# RIGHT: Use semantic memory for facts
await context.memory.store_knowledge(
    content="important_fact",
    metadata={...}
)
```

### ❌ Using Semantic Memory for Workflow State

```python
# WRONG: Not scoped to plan, hard to query
await context.memory.store_knowledge(
    content=f"Step 1 result: {data}"
)
```

```python
# RIGHT: Use working memory for workflow state
state = WorkflowState(context.memory, plan_id)
await state.set("step1_result", data)
```

### ❌ Not Scoping Episodic Properly

```python
# WRONG: Missing user_id breaks isolation
await context.memory.log_interaction(
    agent_id="my-agent",
    role="user",
    content=message
)
```

```python
# RIGHT: Always include user_id
await context.memory.log_interaction(
    agent_id="my-agent",
    role="user",
    content=message,
    user_id=user_id
)
```

### ❌ Loading Too Much History

```python
# WRONG: Expensive, exceeds LLM context limits
history = await context.memory.get_recent_history(
    agent_id="my-agent",
    user_id=user_id,
    limit=1000  # Way too much!
)
```

```python
# RIGHT: Reasonable context window
history = await context.memory.get_recent_history(
    agent_id="my-agent",
    user_id=user_id,
    limit=10  # ~5 turns
)
```

---

## Performance Tips

1. **Batch operations**: Use parallel async calls when possible
2. **Limit results**: Always specify reasonable limits for searches
3. **Cache frequently accessed data**: Don't fetch same knowledge repeatedly
4. **Use metadata**: Helps with future filtering capabilities
5. **Clean up**: Delete plan state after workflow completion (future feature)

---

## Future Enhancements

Planned improvements to Memory Service:

- **Metadata filtering** in semantic search
- **Time-based queries** in episodic memory
- **Automatic state cleanup** for completed workflows
- **Memory compression** for long conversations
- **Cross-plan queries** in working memory (limited)

---

## Additional Resources

- [Semantic Memory Example](../examples/04-memory-semantic/)
- [Episodic Memory Example](../examples/06-memory-episodic/)
- [Working Memory Example](../examples/05-memory-working/)
- [CoALA Framework Paper](https://arxiv.org/abs/2309.02427)
- [SDK Memory Client API](../sdk/python/README.md#memory-client)
- [WorkflowState Helper API](../sdk/python/README.md#workflowstate)
